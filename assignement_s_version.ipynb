{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59e3709e",
   "metadata": {},
   "source": [
    "#  Assignement 2 : clustering + time series\n",
    "\n",
    "## Here is a notebook to make this assignement. The work is a multivariate time series prediction based on energy usage by londonian inhabitant. \n",
    "\n",
    "The dataset is called 'block_0' and is a classical csv file.\n",
    "\n",
    "### For this exercice, you can use whatever you want, for package or resources, to get the best result you can. Many codes and Chatgpt usage can be very helpful if you're blocked by something, or sending us a message, but remember that this task is also made to evaluate your progression.\n",
    "\n",
    "### The objectives is to obtain a good score on prediction of the time series. \n",
    "\n",
    "Some data are not accurate and the dataset contain obviously some errors, and using some preprocessing can be useful. \n",
    "\n",
    "## Main objectives of the task : \n",
    "\n",
    "- 1) Use classical preprocessing, visualization tools and remove or fix errors in the dataset, try to make some assumtion based on the visualization to see which algo. might be useuful for this task.\n",
    "\n",
    "- 2) Try to use clustering algo. on the dataset, as it can be very efficient before to start doing time series prediction\n",
    "\n",
    "- 3) (Feature engineering can also help for this task, even if you're using advanced methods of Deep Learning)\n",
    "\n",
    "- 4) Make your models of forecasting\n",
    "\n",
    "- 5) Evaluate your models, get the best parameters and models\n",
    "\n",
    "- 6) Compare each techniques you used clearly: compare with and without clustering, with different models, $\\textbf{make clear deduction of your result}$\n",
    "\n",
    "Each of these objectives are obviously not precise enough, it's up to you to achieve the objective by adding steps, like preparing the dataset before training the model, and train before evaluate... c\n",
    "\n",
    "## To get a clear evaluation of this task, we split the notebook into section, please respect these sections for your task.\n",
    "\n",
    "### Last thing: as is practice, time and resources consumptions are important, you can write at the end of the notebook what you get. We suppose for this that you do not have access to GPU but if you have, you can also use it and write it. \n",
    "\n",
    "\n",
    "> Here are some package that might be useful, if you want to use more you can, there is no restriction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94336994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Set floating point precision option for pandas\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "# Import seaborn library and set context and style\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "sns.set_style('white')\n",
    "\n",
    "# Import warnings and set filter to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import time library\n",
    "from time import time\n",
    "\n",
    "# Import matplotlib ticker and scipy stats\n",
    "import matplotlib.ticker as tkr\n",
    "from scipy import stats\n",
    "\n",
    "# Import statistical tools for time series analysis\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Import preprocessing from sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Import partial autocorrelation function from statsmodels\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "\n",
    "# Enable inline plotting in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Import math library\n",
    "import math\n",
    "\n",
    "# Import necessary functions from keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "\n",
    "# Import MinMaxScaler from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Import mean squared error and mean absolute error from sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Import early stopping from keras callbacks\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8bcaee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (505, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>energy_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/12/2012</td>\n",
       "      <td>7.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/13/2012</td>\n",
       "      <td>11.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/14/2012</td>\n",
       "      <td>13.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/15/2012</td>\n",
       "      <td>10.2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/16/2012</td>\n",
       "      <td>9.7690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          day  energy_sum\n",
       "0  10/12/2012      7.0980\n",
       "1  10/13/2012     11.0870\n",
       "2  10/14/2012     13.2230\n",
       "3  10/15/2012     10.2570\n",
       "4  10/16/2012      9.7690"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from the file 'household_power_consumption.txt' using pandas\n",
    "# and specify the delimiter as ';'\n",
    "data = pd.read_csv('block_0.csv')\n",
    "\n",
    "# Print the number of rows and columns in the data\n",
    "print('Number of rows and columns:', data.shape)\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b349147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>energy_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2/24/2014</td>\n",
       "      <td>12.5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2/25/2014</td>\n",
       "      <td>11.8260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2/26/2014</td>\n",
       "      <td>12.3280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2/27/2014</td>\n",
       "      <td>20.5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2/28/2014</td>\n",
       "      <td>1.3870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           day  energy_sum\n",
       "500  2/24/2014     12.5280\n",
       "501  2/25/2014     11.8260\n",
       "502  2/26/2014     12.3280\n",
       "503  2/27/2014     20.5180\n",
       "504  2/28/2014      1.3870"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the last 5 rows of the data\n",
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec88821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Information about the dataframe:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   day         505 non-null    object \n",
      " 1   energy_sum  505 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 8.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInformation about the dataframe:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb756b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data type of each column in the dataframe:\n",
      "day            object\n",
      "energy_sum    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData type of each column in the dataframe:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea31c31",
   "metadata": {},
   "source": [
    ">  ## preprocessing and visualization part\n",
    "\n",
    "(some feature engineering can be made here too)\n",
    "\n",
    "If some of you have issue with RAM, you can also use dimensionality reduction techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e3896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c680be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39c11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4026dcea",
   "metadata": {},
   "source": [
    "> ## Clustering part\n",
    "\n",
    "simple kmeans are efficient but you can also try to use more advanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45400ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338320a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230cecca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ffb9c95",
   "metadata": {},
   "source": [
    "> ## Time series model training\n",
    "\n",
    "as you saw in the previous Lab, there is never one 'best' model, so try different model for this task too\n",
    "\n",
    "Remember to check if the model converge correctly, without over/under-fitting !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ceeab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e73348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255fcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fcbb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5085662a",
   "metadata": {},
   "source": [
    "> ## Evaluation of the model\n",
    "\n",
    "Finetuning the hyperparameter can be very long without GPU and server, we do not ask to train 1000 models, just to investigate efficiently this question.\n",
    "\n",
    "For those who want, we suggest you to write the time constrain you decided to use for the training at the end of the notebook, this is also an important part of the work in deep learning\n",
    "\n",
    "Some plot are very good to make a clear visualization of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36abd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5913a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e1dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36bd4064",
   "metadata": {},
   "source": [
    "> ## Comparison, results, deductions and conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f8269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933e9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e4ebf3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06b57137",
   "metadata": {},
   "source": [
    "## resources:\n",
    "\n",
    "- Time: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f5f72",
   "metadata": {},
   "source": [
    "Congratulation ! See you at the exam !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
